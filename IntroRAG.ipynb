{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harigopichandponnekanti/RAGModel/blob/main/IntroRAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B08beuzEhKq0"
      },
      "outputs": [],
      "source": [
        "# Sample dataset with 30 facts about Berlin\n",
        "documents = [\n",
        "    \"Berlin is the capital and largest city of Germany by both area and population.\",\n",
        "    \"Berlin is known for its art scene and modern landmarks like the Berliner Philharmonie.\",\n",
        "    \"The Berlin Wall, which divided the city from 1961 to 1989, was a significant Cold War symbol.\",\n",
        "    \"Berlin has more bridges than Venice, with around 1,700 bridges.\",\n",
        "    \"The city's Zoological Garden is the most visited zoo in Europe and one of the most popular worldwide.\",\n",
        "    \"Berlin's Museum Island is a UNESCO World Heritage site with five world-renowned museums.\",\n",
        "    \"The Reichstag building houses the German Bundestag (Federal Parliament).\",\n",
        "    \"Berlin is famous for its diverse architecture, ranging from historic buildings to modern structures.\",\n",
        "    \"The Berlin Marathon is one of the world's largest and most popular marathons.\",\n",
        "    \"Berlin's public transportation system includes buses, trams, U-Bahn (subway), and S-Bahn (commuter train).\",\n",
        "    \"The Brandenburg Gate is an iconic neoclassical monument in Berlin.\",\n",
        "    \"Berlin has a thriving startup ecosystem and is considered a major tech hub in Europe.\",\n",
        "    \"The city hosts the Berlinale, one of the most prestigious international film festivals.\",\n",
        "    \"Berlin has more than 180 kilometers of navigable waterways.\",\n",
        "    \"The East Side Gallery is an open-air gallery on a remaining section of the Berlin Wall.\",\n",
        "    \"Berlin's Tempelhofer Feld, a former airport, is now a public park and recreational area.\",\n",
        "    \"The TV Tower at Alexanderplatz offers panoramic views of the city.\",\n",
        "    \"Berlin's Tiergarten is one of the largest urban parks in Germany.\",\n",
        "    \"Checkpoint Charlie was a famous crossing point between East and West Berlin during the Cold War.\",\n",
        "    \"Berlin is home to numerous theaters, including the Berliner Ensemble and the Volksbühne.\",\n",
        "    \"The Berlin Philharmonic Orchestra is one of the most famous orchestras in the world.\",\n",
        "    \"Berlin has a vibrant nightlife scene, with countless bars, clubs, and music venues.\",\n",
        "    \"The Berlin Cathedral is a major Protestant church and a landmark of the city.\",\n",
        "    \"Charlottenburg Palace is the largest palace in Berlin and a major tourist attraction.\",\n",
        "    \"Berlin's Alexanderplatz is a large public square and transport hub in central Berlin.\",\n",
        "    \"Berlin is known for its street art, with many murals and graffiti artworks around the city.\",\n",
        "    \"The Gendarmenmarkt is a historic square in Berlin featuring the Konzerthaus, French Cathedral, and German Cathedral.\",\n",
        "    \"Berlin has a strong coffee culture, with numerous cafés throughout the city.\",\n",
        "    \"The Berlin TV Tower is the tallest structure in Germany, standing at 368 meters.\",\n",
        "    \"Berlin's KaDeWe is one of the largest and most famous department stores in Europe.\",\n",
        "    \"The Berlin U-Bahn network has 10 lines and serves 173 stations.\",\n",
        "    \"Berlin has a population of over 3.6 million people.\",\n",
        "    \"The city of Berlin covers an area of 891.8 square kilometers.\",\n",
        "    \"Berlin has a temperate seasonal climate.\",\n",
        "    \"The Berlin International Film Festival, also known as the Berlinale, is one of the world's leading film festivals.\",\n",
        "    \"Berlin is home to the Humboldt University, founded in 1810.\",\n",
        "    \"The Berlin Hauptbahnhof is the largest train station in Europe.\",\n",
        "    \"Berlin's Tegel Airport closed in 2020, and operations moved to Berlin Brandenburg Airport.\",\n",
        "    \"The Spree River runs through the center of Berlin.\",\n",
        "    \"Berlin is twinned with Los Angeles, California, USA.\",\n",
        "    \"The Berlin Botanical Garden is one of the largest and most important botanical gardens in the world.\",\n",
        "    \"Berlin has over 2,500 public parks and gardens.\",\n",
        "    \"The Victory Column (Siegessäule) is a famous monument in Berlin.\",\n",
        "    \"Berlin's Olympic Stadium was built for the 1936 Summer Olympics.\",\n",
        "    \"The Berlin State Library is one of the largest libraries in Europe.\",\n",
        "    \"The Berlin Dungeon is a popular tourist attraction that offers a spooky look at the city's history.\",\n",
        "    \"Berlin's economy is based on high-tech industries and the service sector.\",\n",
        "    \"Berlin is a major center for culture, politics, media, and science.\",\n",
        "    \"The Berlin Wall Memorial commemorates the division of Berlin and the victims of the Wall.\",\n",
        "    \"The city has a large Turkish community, with many residents of Turkish descent.\",\n",
        "    \"Berlin's Mauerpark is a popular park known for its flea market and outdoor karaoke sessions.\",\n",
        "    \"The Berlin Zoological Garden is the oldest zoo in Germany, opened in 1844.\",\n",
        "    \"Berlin is known for its diverse culinary scene, including many vegan and vegetarian restaurants.\",\n",
        "    \"The Berliner Dom is a baroque-style cathedral located on Museum Island.\",\n",
        "    \"The DDR Museum in Berlin offers interactive exhibits about life in East Germany.\",\n",
        "    \"Berlin has a strong cycling culture, with many dedicated bike lanes and bike-sharing programs.\",\n",
        "    \"Berlin's Tempodrom is a multi-purpose event venue known for its unique architecture.\",\n",
        "    \"The Berlinische Galerie is a museum of modern art, photography, and architecture.\",\n",
        "    \"Berlin's Volkspark Friedrichshain is the oldest public park in the city, established in 1848.\",\n",
        "    \"The Hackesche Höfe is a complex of interconnected courtyards in Berlin's Mitte district, known for its vibrant nightlife and art scene.\",\n",
        "    \"Berlin's International Congress Center (ICC) is one of the largest conference centers in the world.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tikenization and Embeddings"
      ],
      "metadata": {
        "id": "Zl-kcGgeC0qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Faiss-cpu library\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "bFivz7RNDBZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the libraries\n",
        "import faiss\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "laAVI8EhEemq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the tokenizer and model for generating embeddings\n",
        "tokenizer=AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
        "model=AutoModel.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "id": "BlgxfaNeE2d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fuction to tokenize the input and generate its embeddings\n",
        "def embed_text(text, tokenizer, model):\n",
        "  # Tokenize the input text,return tensors in pytorch and apply padding\n",
        "    inputs = tokenizer(text,\n",
        "                       return_tensors=\"pt\",\n",
        "                       padding=True,\n",
        "                       truncation=True)\n",
        "    # Disable gradient calculations\n",
        "    with torch.no_grad():\n",
        "      # Pass the tokenized inputs through the model to the last state\n",
        "      embeddings =model(**inputs).last_hidden_state\n",
        "      # Get the embeddings from the model\n",
        "      embeddings=embeddings.mean(dim=1)\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "or7DGqRUFfXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to store the embeddings\n",
        "document_embeddings = []\n",
        "# Loop through the documents to compute the embeddings\n",
        "for doc in documents:\n",
        "  doc_embedding=embed_text(doc, tokenizer, model)\n",
        "  document_embeddings.append(doc_embedding)\n"
      ],
      "metadata": {
        "id": "5SUVdBgRIGCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate  all embeddings into a pytorch tensor,move it to the  CPU and covert to numpy array\n",
        "document_embeddings = torch.cat(document_embeddings).cpu().numpy() # cat means concate\n",
        "document_embeddings"
      ],
      "metadata": {
        "id": "rlY4pRT2I4Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAISS\n",
        "resos to use\n",
        "* Speed\n",
        "* Scalibility\n",
        "* Flexibility\n",
        "# Work flow of FAISS\n",
        "* Indexing\n",
        "* searching (nearest Neighbour words)\n",
        "* Returning t6he Results\n",
        "# Types of FAISS INDEXES\n",
        "\n",
        "* Flat Index(small data)\n",
        "* IVF(Inverted FILE)\n",
        "*  HNSW  (graphbase)\n",
        "# Process\n",
        "\n",
        "\n",
        "1.   Data preparation\n",
        "2.   Index creation\n",
        "3.   Query Processing\n",
        "4.   Similarity searching and resultretrival\n",
        "\n"
      ],
      "metadata": {
        "id": "bpoFl09nZN7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " FAISS TOOL it is the ibrary , developed by Fecebook ai Research , design\n",
        "* for the efficient similarity searches between high- demension vectors\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XBSTiaHCJtl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Retrieval System"
      ],
      "metadata": {
        "id": "YM5SkchSbjWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_embeddings.shape[1]"
      ],
      "metadata": {
        "id": "cmKSnFPocJyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialiaze the FAISS index\n",
        "index =faiss.IndexFlatL2(document_embeddings.shape[1])\n",
        "index.add(document_embeddings)"
      ],
      "metadata": {
        "id": "OghonWrBb0AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import dist\n",
        "# Retrival --> build a function to retreve information\n",
        "def retrieve(query, tokenizer, model, index,documents, top_k=3):\n",
        "  query_embedding =embed_text(query, tokenizer, model)\n",
        "  distances, indices = index.search(query_embedding.numpy(), top_k)\n",
        "  return [documents[i] for i in indices[0]], distances[0]\n"
      ],
      "metadata": {
        "id": "1Ux_NODmcRsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEst the retrival fuction\n",
        "query=\"What is the capital of Germany?\"\n",
        "retrived_docs,distances=retrieve(query, tokenizer, model, index, documents)\n",
        "print(retrived_docs)\n",
        "print(distances)"
      ],
      "metadata": {
        "id": "4keyYliod2fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrating the generative system"
      ],
      "metadata": {
        "id": "CZj0PieYoe6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n"
      ],
      "metadata": {
        "id": "MRPC3C4gelh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the generative tokenizer and model\n",
        "gen_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "gen_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "DjogFoPOo3Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the pad token to the EOS token\n",
        "gen_tokenizer.pad_token =gen_tokenizer.eos_token"
      ],
      "metadata": {
        "id": "TCIqo0pXpL3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the context\n",
        "context=\" \".join(retrived_docs)\n",
        "context"
      ],
      "metadata": {
        "id": "ncBkmYlBqMV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_TB9-O9dGEKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a fuction to generate text\n",
        "def generate_text(context, query,model,tokenizer,max_length=100):\n",
        "  input_text=f\"Context {context} \\n Question: {query} \\n Answer:\"\n",
        "  inputs = tokenizer(input_text, return_tensors=\"pt\",\n",
        "                   padding=True,\n",
        "                   truncation=True)\n",
        "  input_ids=inputs['input_ids']\n",
        "  attention_masks = (input_ids !=tokenizer.pad_token_id).long()\n",
        "  outputs =gen_model.generate(\n",
        "    input_ids,\n",
        "    attention_mask =attention_masks,\n",
        "    max_length=100,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        "\n",
        ")\n",
        "  return tokenizer.decode(outputs[0],skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "nhH46RTxpxf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text the fuction\n",
        "generated_answer=generate_text(context, query, gen_model,  gen_tokenizer)\n",
        "print(f\"Generated Answer: {generated_answer}\")"
      ],
      "metadata": {
        "id": "5Ai43WUSrHfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RAG system"
      ],
      "metadata": {
        "id": "_gPnWXG6xZ6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RAG function then integrates retrievaland generation\n",
        "def rag(query,retrieval_tokenizer,retrieval_model,retrival_index,gen_model,gen_tokinizer, documents, top_k):\n",
        "  retrived_docs,distances=retrieve(query,\n",
        "                                   retrieval_tokenizer,\n",
        "                                   retrieval_model,\n",
        "                                   retrival_index,\n",
        "                                   documents,\n",
        "                                   top_k)\n",
        "  context=\" \".join(retrived_docs)\n",
        "  generated_answer=generate_text(context, query, gen_model,gen_tokenizer)\n",
        "  return generated_answer"
      ],
      "metadata": {
        "id": "fMJBp1L1u_pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test the RAG\n",
        "query=\"What is Berlin famous for?\"\n",
        "answer=rag(query,tokenizer,model,index,gen_model,gen_tokenizer,documents,3)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "7rtrS7eey_hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the RAG system with multiple queries\n",
        "queries=[\"What is the capital of Germany?\",\n",
        "         \"What is berlin famous for?\",\n",
        "         \"Who discovered the way to Brazil\",\n",
        "         \"What is the most famous person in Lesotho?\"]\n",
        "for query in queries:\n",
        "  answer=rag(query,tokenizer,model,index,gen_model,gen_tokenizer,documents,3)\n",
        "  print(query)\n",
        "  print(answer)\n"
      ],
      "metadata": {
        "id": "ZHIAxPrSzTMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Imrove the definition of relevance\n",
        "*   Improve the generation -->explore the parameters\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MJ01in_i3Zhl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Improve the relevance"
      ],
      "metadata": {
        "id": "FsRYO8M_9qT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for query in queries:\n",
        "  retrived_docs,distances=retrieve(query,\n",
        "                                   tokenizer,\n",
        "                                   model,\n",
        "                                   index,\n",
        "                                   documents,\n",
        "                                   3)\n",
        "  print(retrived_docs)\n",
        "  print(distances)\n",
        "\n"
      ],
      "metadata": {
        "id": "y6N2fqzN2vow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that checks for relevance\n",
        "# if the distance if 40, distard the document\n",
        "def is_relevant(distance, threshold=40):\n",
        "    return distance < threshold"
      ],
      "metadata": {
        "id": "IVsBwd4I-nVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RAG function then integrates retrievaland generation\n",
        "def rag(query,retrieval_tokenizer,retrieval_model,retrival_index,gen_model,gen_tokinizer, documents, top_k):\n",
        "  retrived_docs,distances=retrieve(query,\n",
        "                                   retrieval_tokenizer,\n",
        "                                   retrieval_model,\n",
        "                                   retrival_index,\n",
        "                                   documents,\n",
        "                                   top_k)\n",
        "  # Discard all the documents that  do not meet the relavence\n",
        "  relevant_docs=[doc for doc,distance in zip(retrived_docs,distances) if is_relevant(distance,40)]\n",
        "  # add a message if no\n",
        "  if not relevant_docs:\n",
        "    return \"I am sorry,there is no relevent information\"\n",
        "\n",
        "  context=\" \".join(relevant_docs)\n",
        "  generated_answer=generate_text(context, query, gen_model,gen_tokenizer)\n",
        "  return generated_answer"
      ],
      "metadata": {
        "id": "zZYkNhZgGJgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the rag\n",
        "\n",
        "for query in queries:\n",
        "  answer=rag(query,tokenizer,model,index,gen_model,gen_tokenizer,documents,3)\n",
        "  print(query)\n",
        "  print(answer)"
      ],
      "metadata": {
        "id": "PMxba5sMHncZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main things in the RAG\n",
        "* Temperature\n",
        "   means it adjustes the randomness genration text ,balancing between focused & creative outputs\n",
        "    *  temperature=1 (default)\n",
        "    *  LowerTemperature (less then 1) focused output `preferable`\n",
        "    *  Higher Temperature (greater than 1)  Random output :\n",
        "* Top K Sampling\n",
        "      meansIt restricts choices for next word to top K options , enhancing coherence & reducing randomness\n",
        "      `example`. top_k =50  This setting limits the model to the top 50 next words ,filtering out unlikely options and reducing noice\n",
        "\n",
        "* Top-p (Nucleus) Samplingmeans it adjusts word options based on cumulative probability, balncing diversity and coherence `Example `\n",
        "top_p =1  the setting considers all options with a cumulative probability up to 100 % .Lower values lomit options , like top_k\n",
        "\n",
        "\n",
        "* Repetation Penalty  means reduces repetitive phrases more diverse and human-like   example :   Repetition_penalty =1.1   this setting  prevents the model from repetating words ,ensuring more varied output\n",
        "\n",
        "\n",
        "\n",
        "*  Sampling Mode  : means  sampling mode adds randomness ,creating more varied and creative text\n",
        "Example:  Do_sample =True    this activates sampling mode enabling m,ore varied and cretive outputs\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "`Example main   Question  what are  the benifits of a plant based diet `\n",
        "`\n",
        "  1.  temperature =0.7  focused but slightly creative\n",
        "\n",
        "  2. top-k =50  having top 50 words are swelective\n",
        "\n",
        "  3. top_0.9\n",
        "  4. repetation penality=1.1\n",
        "  5. sampling mode = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  we can adjust the parameters   \n",
        "   "
      ],
      "metadata": {
        "id": "Xg5LaCohIM8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improve the genration system"
      ],
      "metadata": {
        "id": "-qU1GAq_FejM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a fuction to generate text\n",
        "def generate_text(context, query,model,tokenizer,max_length=100):\n",
        "  input_text=f\"Context {context} \\n Question: {query} \\n Answer:\"\n",
        "  inputs = tokenizer(input_text, return_tensors=\"pt\",\n",
        "                   padding=True,\n",
        "                   truncation=True)\n",
        "  input_ids=inputs['input_ids']\n",
        "  attention_masks = (input_ids !=tokenizer.pad_token_id).long()\n",
        "  outputs =gen_model.generate(\n",
        "    input_ids,\n",
        "    attention_mask =attention_masks,\n",
        "    max_length=100,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    tempature=0.1,\n",
        "    top_k=50,\n",
        "    top_p=0.9,\n",
        "    repetition_penalty=1.1,\n",
        "    do_sample=True\n",
        "\n",
        "\n",
        ")\n",
        "  return tokenizer.decode(outputs[0],skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "GPZuLHc8FuTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RAG function then integrates retrievaland generation\n",
        "def rag(query,retrieval_tokenizer,retrieval_model,retrival_index,gen_model,gen_tokinizer, documents, top_k):\n",
        "  retrived_docs,distances=retrieve(query,\n",
        "                                   retrieval_tokenizer,\n",
        "                                   retrieval_model,\n",
        "                                   retrival_index,\n",
        "                                   documents,\n",
        "                                   top_k)\n",
        "  # Discard all the documents that  do not meet the relavence\n",
        "  relevant_docs=[doc for doc,distance in zip(retrived_docs,distances) if is_relevant(distance,40)]\n",
        "  # add a message if no\n",
        "  if not relevant_docs:\n",
        "    return \"I am sorry,there is no relevent information\"\n",
        "\n",
        "  context=\" \".join(relevant_docs)\n",
        "  generated_answer=generate_text(context, query, gen_model,gen_tokenizer)\n",
        "  return generated_answer"
      ],
      "metadata": {
        "id": "1mD-UXJqGnBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for query in queries:\n",
        "  retrived_docs,distances=retrieve(query,\n",
        "                                   tokenizer,\n",
        "                                   model,\n",
        "                                   index,\n",
        "                                   documents,\n",
        "                                   3)\n",
        "  print(query)\n",
        "  print(retrived_docs)\n",
        "  print(distances)"
      ],
      "metadata": {
        "id": "LPhGlzGDHKkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "62Zt5-gCHiQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}